{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(remote-memory-access)=\n",
    "# Remote Memory Access\n",
    "\n",
    "In {numref}`mpi-hello-world`, we introduced two communication modes: two-sided and one-sided. The point-to-point and collective communications discussed in the earlier sections focus on two-sided communication. This section specifically delves into one-sided communication, also known as Remote Memory Access (RMA).\n",
    "\n",
    "## Window\n",
    "\n",
    "Any memory allocated by a process is private, meaning it is only accessible by the process itself. To enable remote memory access, exposing a portion of a process's private memory for access by other processes requires special handling. In MPI, a Window is used to define a memory region that can be accessed remotely. A designated memory region is set to allow remote access, and all processes within the Window can read and write to this shared region. {numref}`rma-window` provides a detailed explanation of private memory regions and windows that can be accessed remotely. The [`mpi4py.MPI.Win`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win) class in mpi4py facilitates Window-related operations.\n",
    "\n",
    "```{figure} ../img/ch-mpi/rma-window.svg\n",
    "---\n",
    "width: 600px\n",
    "name: rma-window\n",
    "---\n",
    "Private memory regions and remotely accessible windows\n",
    "```\n",
    "\n",
    "## Creating a Window\n",
    "\n",
    "Window can be created using [`mpi4py.MPI.Win.Allocate`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win.Allocate) and [`mpi4py.MPI.Win.Create`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win.Create). The `mpi4py.MPI.Win.Allocate` method creates a new memory buffer that can be accessed remotely, while `mpi4py.MPI.Win.Create` designates an existing memory buffer for remote access. Specifically, the distinction lies in the first parameter of these two methods: `mpi4py.MPI.Win.Allocate(size)` takes `size` bytes to create a new memory buffer, whereas `mpi4py.MPI.Win.Create(memory)` takes the memory address `memory` of an existing buffer.\n",
    "\n",
    "## Read and Write Operations\n",
    "\n",
    "Once a Window with remote access is created, three types of methods can be used to read and write data to the memory region: [`mpi4py.MPI.Win.Put`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win.Put), [`mpi4py.MPI.Win.Get`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win.Get), and [`mpi4py.MPI.Win.Accumulate`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.Win.html#mpi4py.MPI.Win.Accumulate). These methods all take two parameters: `origin` and `target_rank`, representing the source process and the target process, respectively. The source process is the one invoking the read/write method, while the target process is the remote process.\n",
    "\n",
    "- `Win.Put` moves data from the origin process to the target process.\n",
    "- `Win.Get` moves data from the target process to the origin process.\n",
    "- `Win.Accumulate` is similar to `Win.Put`, moving data from the origin process to the target process, while also performing an aggregation operation on the data from the source and target processes. Aggregation operators include [`mpi4py.MPI.SUM`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.SUM.html), [`mpi4py.MPI.PROD`](https://mpi4py.readthedocs.io/en/stable/reference/mpi4py.MPI.PROD.html), and others.\n",
    "\n",
    "## Data Synchronization\n",
    "\n",
    "In a single-machine program, execution is sequential. However, in a multi-machine environment where multiple processes are involved in reading and writing data, data synchronization issues may arise. As illustrated in {numref}`rma-sync-problem`, without explicit control over the order of read and write operations, the data in a particular memory region may not yield the expected results.\n",
    "\n",
    "```{figure} ../img/ch-mpi/rma-sync-problem.png\n",
    "---\n",
    "width: 500px\n",
    "name: rma-sync-problem\n",
    "---\n",
    "Data Synchronization in Parallel I/O, P0 and P1 stand for two processed.\n",
    "```\n",
    "\n",
    "To address this problem, various data synchronization mechanisms are available in MPI, broadly categorized into Active Target Synchronization and Passive Target Synchronization, as illustrated in {numref}`rma-synchronization`.\n",
    "\n",
    "```{figure} ../img/ch-mpi/rma-synchronization.png\n",
    "---\n",
    "width: 800px\n",
    "name: rma-synchronization\n",
    "---\n",
    "Active Target Synchronization and Passive Target Synchronization.\n",
    "```\n",
    "\n",
    "## Example: Remote Read and Write\n",
    "\n",
    "A complete RMA (Remote Memory Access) program should encompass the following steps:\n",
    "\n",
    "1. Create a window\n",
    "2. Implement data synchronization\n",
    "3. Perform data read and write operations\n",
    "\n",
    "Example code for a case study is illustrated in {numref}`mpi-rma-lock` and is saved as `rma-lock.py`.\n",
    "\n",
    "```{code-block} python\n",
    ":caption: rma-lock.py\n",
    ":name: mpi-rma-lock\n",
    "\n",
    "import numpy as np\n",
    "from mpi4py import MPI\n",
    "from mpi4py.util import dtlib\n",
    "\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()\n",
    "\n",
    "datatype = MPI.FLOAT\n",
    "np_dtype = dtlib.to_numpy_dtype(datatype)\n",
    "itemsize = datatype.Get_size()\n",
    "\n",
    "N = 8\n",
    "win_size = N * itemsize if rank == 0 else 0\n",
    "win = MPI.Win.Allocate(win_size, comm=comm)\n",
    "\n",
    "buf = np.empty(N, dtype=np_dtype)\n",
    "if rank == 0:\n",
    "    buf.fill(42)\n",
    "    win.Lock(rank=0)\n",
    "    win.Put(buf, target_rank=0)\n",
    "    win.Unlock(rank=0)\n",
    "    comm.Barrier()\n",
    "else:\n",
    "    comm.Barrier()\n",
    "    win.Lock(rank=0)\n",
    "    win.Get(buf, target_rank=0)\n",
    "    win.Unlock(rank=0)\n",
    "    if np.all(buf == 42):\n",
    "        print(f\"win.Get successfully on Rank {comm.Get_rank()}.\")\n",
    "    else:\n",
    "        print(f\"win.Get failed on Rank {comm.Get_rank()}.\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "win.Get successfully on Rank 4.\n",
      "win.Get successfully on Rank 5.\n",
      "win.Get successfully on Rank 6.\n",
      "win.Get successfully on Rank 7.\n",
      "win.Get successfully on Rank 1.\n",
      "win.Get successfully on Rank 2.\n",
      "win.Get successfully on Rank 3.\n"
     ]
    }
   ],
   "source": [
    "!mpiexec -np 8 python rma_lock.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dispy",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
